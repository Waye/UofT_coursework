{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Assignment3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Waye/CSC420-CourseWork-fall2019/blob/master/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        },
        "id": "VcjIKRlORJQL",
        "colab_type": "text"
      },
      "source": [
        "# 1.Image Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zza-_h0Kms6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper funtion\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from skimage import io, transform\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from nn import Net\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "class CatDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_dir, pkl, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        with open(pkl, 'rb') as f:\n",
        "            self.data = pickle.load(f)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if torch.is_tensor(index):\n",
        "            index = index.tolist()\n",
        "        \n",
        "        cat_name = os.path.join(self.root_dir, 'input/', self.data[index][0])\n",
        "        seg_name = os.path.join(self.root_dir, 'mask/', self.data[index][1])\n",
        "        cat = io.imread(cat_name)\n",
        "        segmentation = io.imread(seg_name)\n",
        "        if cat.shape[-1] != 3:\n",
        "            print(cat.shape[-1])\n",
        "            print(cat_name)\n",
        "            exit()\n",
        "\n",
        "        sample = {'cat': cat, 'mask': segmentation}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "class Rescale(object):\n",
        "    \"\"\"Rescale the image in a sample to a given size.\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If tuple, output is\n",
        "            matched to output_size. If int, smaller of image edges is matched\n",
        "            to output_size keeping aspect ratio the same.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        cat, mask = sample['cat'], sample['mask']\n",
        "\n",
        "        h, w = cat.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "        cat = transform.resize(cat, (new_h, new_w))\n",
        "\n",
        "        h, w = mask.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "        \n",
        "        mask = transform.resize(mask, (new_h, new_w))\n",
        "        mask[mask > 0.5] = 1\n",
        "        mask[mask <= 0.5] = 0  ### FUUUUUUU\n",
        "        return {'cat': cat, 'mask': mask}\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        cat, mask = sample['cat'], sample['mask']\n",
        "\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C X H X W\n",
        "        cat = cat.transpose((2, 0, 1))\n",
        "        mask = mask.reshape((128, 128, 1)).astype(np.float_)\n",
        "        mask = mask.transpose((2, 0, 1))\n",
        "        return {'cat': torch.from_numpy(cat),\n",
        "                'mask': torch.from_numpy(mask)}\n",
        "\n",
        "\n",
        "\n",
        "def step(net, cats, masks, criteria, optimizer):\n",
        "    cats = cats.unsqueeze(0).float()\n",
        "    predicted_mask = net(cats)\n",
        "    loss = criteria(predicted_mask[0], masks.float())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train(net, epochs, batch_size, criteria, optimizer, trainset, testset):\n",
        "    num_iter = len(trainset)\n",
        "    best = 0.0\n",
        "    for e in range(epochs):\n",
        "        print(f'Beginning epoch {e+1}')\n",
        "        net.train()\n",
        "        loss = 0\n",
        "        for i in range(num_iter):\n",
        "            sample = trainset[i]\n",
        "            cat = sample['cat']\n",
        "            mask = sample['mask']\n",
        "            if use_gpu:\n",
        "                cat = cat.cuda()\n",
        "                mask = mask.cuda()\n",
        "            loss += step(net, cat, mask, criteria, optimizer)\n",
        "        print(f\"Epoch #{e+1}\")\n",
        "        print(f\"Total loss: {loss}\")\n",
        "        net.eval()\n",
        "        test_p = performance_sorensen(net, testset)\n",
        "        # if test_p > best:  # If you want to save the model\n",
        "            # best = test_p            \n",
        "            # torch.save(net.state_dict(), f'q1/checkpoints_{e+1}.pt')\n",
        "\n",
        "\n",
        "def calculate_sorensen(arr1, arr2):\n",
        "    return np.sum(np.equal(arr1, arr2)) / np.size(arr1)\n",
        "\n",
        "\n",
        "def performance_sorensen(net, dataset):\n",
        "    scale = Rescale((128, 128))\n",
        "\n",
        "    sorensen = 0\n",
        "    for i in range(len(dataset)):\n",
        "        sample = dataset[i]\n",
        "        cat = sample['cat']\n",
        "        mask = sample['mask']\n",
        "        if use_gpu:\n",
        "            cat = cat.cuda()\n",
        "        predicted_mask = net(cat.unsqueeze(0).float())\n",
        "        img = predicted_mask.detach().cpu().numpy()[0,0,:,:]\n",
        "        img[img > 0.5] = 1\n",
        "        img[img <= 0.5] = 0\n",
        "        truth = mask.numpy()[0,:,:]\n",
        "        coeff = calculate_sorensen(img, truth)\n",
        "        sorensen += coeff\n",
        "    print(f'Average sorensen-dice coefficient: {sorensen / len(dataset)}')\n",
        "    return sorensen / len(dataset)\n",
        "\n",
        "\n",
        "class DiceLoss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, predict, target):\n",
        "        predict = predict.contiguous()\n",
        "        target = target.contiguous()\n",
        "\n",
        "        intersect = (predict * target).sum(dim=1).sum(dim=1)\n",
        "        \n",
        "        loss = (1 - ((2. * intersect + 1.) / (predict.sum(dim=1).sum(dim=1) + target.sum(dim=1).sum(dim=1) + 1.)))\n",
        "\n",
        "        return loss.mean()\n",
        "\n",
        "\n",
        "class BCELoss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BCELoss, self).__init__()\n",
        "    \n",
        "    def forward(self, predict, target):\n",
        "        return F.binary_cross_entropy(predict, target, reduction='mean')\n",
        "\n",
        "\n",
        "def main(do_train):\n",
        "    scale = Rescale((128, 128))\n",
        "    trainset = CatDataset('cat_data/Train/', 'train.pkl', transform=transforms.Compose([scale, ToTensor()]))\n",
        "    # trainset = CatDataset('cat_data/AugmentedTrain/', 'aug_train.pkl', transform=transforms.Compose([scale, ToTensor()]))\n",
        "    # trainset = CatDataset('transfer/Train', 'transfer_train.pkl', transform=transforms.Compose([scale, ToTensor()]))\n",
        "    testset = CatDataset('cat_data/Test/', 'test.pkl', transform=transforms.Compose([scale, ToTensor()]))\n",
        "\n",
        "    net = Net()\n",
        "    if use_gpu:\n",
        "        net = net.cuda()\n",
        "\n",
        "    batch_size = 1\n",
        "    epochs = 50\n",
        "\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.99)\n",
        "    criteria = BCELoss()\n",
        "    # criteria = DiceLoss()\n",
        "\n",
        "    train(net, epochs, batch_size, criteria, optimizer, trainset, testset)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lfbp7x8cRJQN",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Implement U-NET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB7TO7aGVXuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nn.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def downsample_block(self, input_size, output_size):\n",
        "        return torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(input_size, output_size, 3, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.BatchNorm2d(output_size),\n",
        "            torch.nn.Conv2d(output_size, output_size, 3, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.BatchNorm2d(output_size),\n",
        "        )\n",
        "\n",
        "    def upsample_block(self, input_size, output_size):\n",
        "        return torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(input_size, output_size, 3, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.BatchNorm2d(output_size),\n",
        "            torch.nn.Conv2d(output_size, output_size, 3, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.BatchNorm2d(output_size),\n",
        "        )\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # NOTE: (3, 64, 3) instead of (1, 64, 3) due to color images\n",
        "        self.down_conv1 = self.downsample_block(3, 64)\n",
        "        self.down_conv2 = self.downsample_block(64, 128)\n",
        "        self.down_conv3 = self.downsample_block(128, 256)\n",
        "        self.down_conv4 = self.downsample_block(256, 512)\n",
        "        self.down_conv5 = self.downsample_block(512, 1024)\n",
        "\n",
        "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
        "        self.up_conv4 = self.upsample_block(1024, 512)\n",
        "        self.up3 = nn.ConvTranspose2d(512,256, 2, stride=2)\n",
        "        self.up_conv3 = self.upsample_block(512, 256)\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.up_conv2 = self.upsample_block(256, 128)\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.up_conv1 = self.upsample_block(128, 64)\n",
        "\n",
        "        self.final_conv = torch.nn.Conv2d(64, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip1 = self.down_conv1(x)\n",
        "        downsample1 = F.max_pool2d(skip1, 2)\n",
        "        skip2 = self.down_conv2(downsample1)\n",
        "        downsample2 = F.max_pool2d(skip2, 2)\n",
        "        skip3 = self.down_conv3(downsample2)\n",
        "        downsample3 = F.max_pool2d(skip3, 2)\n",
        "        skip4 = self.down_conv4(downsample3)\n",
        "        downsample4 = F.max_pool2d(skip4, 2)\n",
        "        downsample5 = self.down_conv5(downsample4)\n",
        "        upsample4 = self.up4(downsample5)\n",
        "        upsample4 = torch.cat((skip4, upsample4), dim=1)\n",
        "        upsample4 = self.up_conv4(upsample4)\n",
        "        upsample3 = self.up3(upsample4)\n",
        "        upsample3 = torch.cat((skip3, upsample3), dim=1)\n",
        "        upsample3 = self.up_conv3(upsample3)\n",
        "        upsample2 = self.up2(upsample3)\n",
        "        upsample2 = torch.cat((skip2, upsample2), dim=1)\n",
        "        upsample2 = self.up_conv2(upsample2)\n",
        "        upsample1 = self.up1(upsample2)\n",
        "        upsample1 = torch.cat((skip1, upsample1), dim=1)\n",
        "        upsample1 = self.up_conv1(upsample1)\n",
        "        x = self.final_conv(upsample1)\n",
        "        return F.sigmoid(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Dum0X7RJQO",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGPxC_SbVjnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "e771e767-49f0-4c5e-b50c-dd9c17c0cd23"
      },
      "source": [
        "# augment.py\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from skimage import io, transform\n",
        "\n",
        "AUG = 'cat_data/AugmentedTrain/'\n",
        "TRAIN = 'cat_data/Train'\n",
        "\n",
        "for f in os.listdir(TRAIN + '/input'):\n",
        "    cat = io.imread(TRAIN + '/input/' + f)\n",
        "    mask = io.imread(TRAIN + '/mask/mask_' + f)\n",
        "\n",
        "    # Do a flip left-right\n",
        "    # flip_cat = np.fliplr(cat)\n",
        "    # flip_mask = np.fliplr(mask)\n",
        "    \n",
        "    # io.imsave(AUG + '/input/flip' + f, flip_cat)\n",
        "    # io.imsave(AUG + '/mask/flip_mask_' + f, flip_mask)\n",
        "\n",
        "    # Do an upside down flip\n",
        "    # updown_cat = np.flipud(cat)\n",
        "    # updown_mask = np.flipud(mask)\n",
        "    # io.imsave(AUG + '/input/updown' + f, updown_cat)\n",
        "    # io.imsave(AUG + '/mask/updown_mask_' + f, updown_mask)\n",
        "    \n",
        "    # Do a 90 degree rotation right\n",
        "    # right_cat = transform.rotate(cat, 90, resize=True)\n",
        "    # right_mask = transform.rotate(mask, 90, resize=True)\n",
        "    # io.imsave(AUG + '/input/right' + f, right_cat)\n",
        "    # io.imsave(AUG + '/mask/right_mask_' + f, right_mask)\n",
        "\n",
        "    # Do a 90 degree rotation left\n",
        "    # left_cat = transform.rotate(cat, 270, resize=True)\n",
        "    # left_mask = transform.rotate(mask, 270, resize=True)\n",
        "    # io.imsave(AUG + '/input/left' + f, left_cat)\n",
        "    # io.imsave(AUG + '/mask/left_mask_' + f, left_mask)\n",
        "\n",
        "    # Do a random crop)\n",
        "    # print(cat.shape)\n",
        "    # crop_len = np.random.randint(0, max(min(cat.shape[0] - 150, cat.shape[1] - 150), 1)) // 4\n",
        "    # crop_cat = cat[crop_len:cat.shape[0] - crop_len, crop_len:cat.shape[1]-crop_len,:]\n",
        "    # crop_mask = mask[crop_len:cat.shape[0] - crop_len, crop_len:cat.shape[1]-crop_len]\n",
        "    # io.imsave(AUG + '/input/crop' + f, crop_cat)\n",
        "    # io.imsave(AUG + '/mask/crop_mask_' + f, crop_mask)\n",
        "\n",
        "    # Do a horizontal stretch\n",
        "    # stretch_cat = transform.resize(cat, (cat.shape[0], int(cat.shape[1]*1.5)))\n",
        "    # stretch_mask = transform.resize(mask, (mask.shape[0], int(mask.shape[1]*1.5)))\n",
        "    # io.imsave(AUG + '/input/hstretch' + f, stretch_cat)\n",
        "    # io.imsave(AUG + '/mask/hstretch_mask_' + f, stretch_mask)\n",
        "\n",
        "    # stretch_cat = transform.resize(cat, (int(cat.shape[0] * 1.5), cat.shape[1]))\n",
        "    # stretch_mask = transform.resize(mask, (int(mask.shape[0] * 1.5), mask.shape[1]))\n",
        "    # io.imsave(AUG + '/input/vstretch' + f, stretch_cat)\n",
        "    # io.imsave(AUG + '/mask/vstretch_mask_' + f, stretch_mask)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-804900ed9d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mTRAIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cat_data/Train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/input/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/mask/mask_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cat_data/Train/input'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMvcvXkjRJQP",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBmcR0flW6Cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6krx16U-RJQP",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 Visualizing segmentation predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsXGK_PTTpqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "from nn import Net\n",
        "from skimage import io, feature, transform\n",
        "\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "def binary_mask(arr):\n",
        "    arr[arr > 0.5] = 1\n",
        "    arr[arr <= 0.5] = 0\n",
        "\n",
        "\n",
        "def process_cat(cat):\n",
        "    h, w = cat.shape[:2]\n",
        "    output_size = (128, 128)\n",
        "    if isinstance(output_size, int):\n",
        "        if h > w:\n",
        "            new_h, new_w = output_size * h / w, output_size\n",
        "        else:\n",
        "            new_h, new_w = output_size, output_size * w / h\n",
        "    else:\n",
        "        new_h, new_w = output_size\n",
        "\n",
        "    new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "    sized_cat = transform.resize(cat, (new_h, new_w))\n",
        "    sized_cat = sized_cat.transpose((2, 0, 1))\n",
        "    cat_tensor = torch.from_numpy(sized_cat)\n",
        "    return cat_tensor\n",
        "\n",
        "\n",
        "def plot_seg(image, net):\n",
        "    cat = io.imread(image)\n",
        "    cat_tensor = process_cat(cat)\n",
        "    \n",
        "    if use_gpu:\n",
        "        cat_tensor = cat_tensor.cuda()\n",
        "    cat_mask = net(cat_tensor.unsqueeze(0).float())\n",
        "    img = cat_mask.detach().cpu().numpy()[0,0,:,:]\n",
        "    resized_mask = transform.resize(img, cat.shape[0:2], anti_aliasing=False, preserve_range=True)\n",
        "    binary_mask(resized_mask)\n",
        "    resized_mask = (resized_mask * 255).astype(np.uint8)\n",
        "    ret, thresh = cv2.threshold(resized_mask, 127,255, 0)\n",
        "    _, contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cv2.drawContours(cat, contours, -1, (0,255,0), 3)\n",
        "    return cat\n",
        "\n",
        "\n",
        "def plot_mask(image, net):\n",
        "    cat = io.imread(image[0])\n",
        "    cat_tensor = process_cat(cat)\n",
        "    truth = io.imread(image[1])\n",
        "\n",
        "    if use_gpu:\n",
        "        cat_tensor = cat_tensor.cuda()\n",
        "    cat_mask = net(cat_tensor.unsqueeze(0).float())\n",
        "    mask = cat_mask.detach().cpu().numpy()[0,0,:,:]\n",
        "    resized_mask = transform.resize(mask, cat.shape[0:2], anti_aliasing=False, preserve_range=True)\n",
        "    binary_mask(resized_mask)\n",
        "    return cat, truth, resized_mask\n",
        "\n",
        "\n",
        "def main(images, mask=False):\n",
        "    net = Net()\n",
        "    if use_gpu:\n",
        "        device = torch.device('cuda')\n",
        "        net.load_state_dict(torch.load('q1_checkpoints/q1_2_dice_20.pt'))\n",
        "        net.to(device)\n",
        "    else:\n",
        "        net.load_state_dict(torch.load('q1_checkpoints/q1_2_bce_35.pt', map_location='cpu'))\n",
        "    \n",
        "    if mask:\n",
        "        fig = plt.figure(figsize=(16, 20))\n",
        "        l = len(images) // 2 + 1\n",
        "        for i in range(len(images) // 2):\n",
        "            cat, truth, pred = plot_mask(images[2 * i], net)\n",
        "            a = fig.add_subplot(l, 6, i*6 + 1)\n",
        "            imgplot = plt.imshow(cat)\n",
        "            if i == 0: a.set_title('Cat')\n",
        "            a = fig.add_subplot(l, 6, i*6 + 2)\n",
        "            imgplot = plt.imshow(truth, cmap='gray')\n",
        "            if i == 0: a.set_title('Groundtruth')\n",
        "            a = fig.add_subplot(l, 6, i*6 + 3)\n",
        "            imgplot = plt.imshow(pred, cmap='gray')\n",
        "            if i == 0: a.set_title('Prediction')\n",
        "            cat, truth, pred = plot_mask(images[2 * i + 1], net)\n",
        "            a = fig.add_subplot(l, 6, i*6 + 4)\n",
        "            imgplot = plt.imshow(cat)\n",
        "            if i == 0: a.set_title('Cat')\n",
        "            a = fig.add_subplot(l, 6, i*6 + 5)\n",
        "            imgplot = plt.imshow(truth, cmap='gray')\n",
        "            if i == 0: a.set_title('Groundtruth')\n",
        "            a = fig.add_subplot(l, 6, i*6 + 6)\n",
        "            imgplot = plt.imshow(pred, cmap='gray')\n",
        "            if i == 0: a.set_title('Prediction')\n",
        "        if len(images) % 2 != 0:\n",
        "            cat, truth, pred = plot_mask(images[-1], net)\n",
        "            a = fig.add_subplot(l, 6, i*6 + 7)\n",
        "            imgplot = plt.imshow(cat)\n",
        "            a = fig.add_subplot(l, 6, i*6 + 8)\n",
        "            imgplot = plt.imshow(truth, cmap='gray')\n",
        "            a = fig.add_subplot(l, 6, i*6 + 9)\n",
        "            imgplot = plt.imshow(pred, cmap='gray')\n",
        "        plt.savefig('vis1_2_dice', bbox_inches='tight')\n",
        "    else:\n",
        "        i = 1\n",
        "        for image in images:\n",
        "            cat = plot_seg(image[0], net)\n",
        "            plt.imsave(f'seg{i}.png', cat)\n",
        "            i += 1\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Visualize cat segmentations')\n",
        "    parser.add_argument('root', type=str, help='path to where files are located')\n",
        "    parser.add_argument('pickle', type=str, help='pickle file containing list of filenames')\n",
        "    parser.add_argument('--mask', action=\"store_true\", help='display mask instead of outline')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    f = open(args.pickle, 'rb')\n",
        "    files = pickle.load(f)\n",
        "    new_files = []\n",
        "    for file in files:\n",
        "        new_files.append((args.root + 'input/' + file[0], args.root + 'mask/' + file[1]))\n",
        "    main(new_files, args.mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdo13JV7RJQQ",
        "colab_type": "text"
      },
      "source": [
        "# 2.Bounding Box Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EykXwasRJQR",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Problem definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9ZnuPKHRJQR",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErR-l7POZWQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Number of parameters:\n",
        "        # (5 * 5 * 1 + 2) * 16 = 324\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # Number of parameters\n",
        "        # (5 * 5 * 16 + 2) * 32 = 12832\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # Number of parameters\n",
        "        # (3 * 3 * 32 + 1) * 64) = 18496\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # Number of parameters:\n",
        "        # (3 * 3 * 64 + 1) * 128 = 73856\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # Number of parameters\n",
        "        # 12 * 12 * 128 * 3 = 55296\n",
        "        self.fc = nn.Linear(12*12*128, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDWkkHabRJQS",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 IOU Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrAMwxiXbd5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from shapely.geometry.point import Point\n",
        "from skimage.color import gray2rgb\n",
        "from skimage.draw import circle, circle_perimeter_aa\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "from nn_q2 import Net\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "class CircleDataset(Dataset):\n",
        "\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "        self.seeds = [np.random.randint(1, 2147483647) for i in range(size)]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        seed = self.seeds[index]\n",
        "        np.random.seed(seed)\n",
        "        param, img = noisy_circle(200, 50, 2)\n",
        "        np.random.seed(None)\n",
        "        return img, param\n",
        "\n",
        "\n",
        "def draw_circle(img, row, col, rad):\n",
        "    rr, cc, val = circle_perimeter_aa(row, col, rad)\n",
        "    valid = (\n",
        "        (rr >= 0) &\n",
        "        (rr < img.shape[0]) &\n",
        "        (cc >= 0) &\n",
        "        (cc < img.shape[1])\n",
        "    )\n",
        "    img[rr[valid], cc[valid]] = val[valid]\n",
        "\n",
        "\n",
        "def noisy_circle(size, radius, noise):\n",
        "    img = np.zeros((size, size), dtype=np.float)\n",
        "\n",
        "    # Circle\n",
        "    row = np.random.randint(size)\n",
        "    col = np.random.randint(size)\n",
        "    rad = np.random.randint(10, max(10, radius))\n",
        "    draw_circle(img, row, col, rad)\n",
        "\n",
        "    # Noise\n",
        "    img += noise * np.random.rand(*img.shape)\n",
        "    return (row, col, rad), img\n",
        "\n",
        "\n",
        "def find_circle(img):\n",
        "    # Load the CNNs\n",
        "    netx = Net()\n",
        "    nety = Net()\n",
        "    netr = Net()\n",
        "    device = torch.device('cuda')\n",
        "    netx.load_state_dict(torch.load('q2x.pt'))\n",
        "    nety.load_state_dict(torch.load('q2y.pt'))\n",
        "    netr.load_state_dict(torch.load('q2r.pt'))\n",
        "    netx.to(device)\n",
        "    nety.to(device)\n",
        "    netr.to(device)\n",
        "\n",
        "    # Test the image\n",
        "    img_tensor = img.reshape(200, 200, 1).transpose((2, 0, 1))\n",
        "    tensor = torch.from_numpy(img_tensor)\n",
        "    if use_gpu:\n",
        "        tensor = tensor.cuda()\n",
        "    tensor = tensor.unsqueeze(1).float()\n",
        "    resx = netx(tensor).detach().cpu().numpy()[0]\n",
        "    resy = nety(tensor).detach().cpu().numpy()[0]\n",
        "    resr = netr(tensor).detach().cpu().numpy()[0]\n",
        "    return int(resx), int(resy), int(resr)\n",
        "\n",
        "\n",
        "def iou(params0, params1):\n",
        "    row0, col0, rad0 = params0\n",
        "    row1, col1, rad1 = params1\n",
        "\n",
        "    shape0 = Point(row0, col0).buffer(rad0)\n",
        "    shape1 = Point(row1, col1).buffer(rad1)\n",
        "\n",
        "    return (\n",
        "        shape0.intersection(shape1).area /\n",
        "        shape0.union(shape1).area\n",
        "    )\n",
        "\n",
        "\n",
        "def observe():\n",
        "    '''\n",
        "    Plot the groundtruth bounding circle and the predicted bounding circle.\n",
        "    The groundtruth is in green and the prediction in red.\n",
        "    '''\n",
        "    for _ in range(10):\n",
        "        netx = Net()\n",
        "        nety = Net()\n",
        "        netr = Net()\n",
        "        device = torch.device('cuda')\n",
        "        netx.load_state_dict(torch.load('q2x.pt'))\n",
        "        nety.load_state_dict(torch.load('q2y.pt'))\n",
        "        netr.load_state_dict(torch.load('q2r.pt'))\n",
        "        netx.to(device)\n",
        "        nety.to(device)\n",
        "        netr.to(device)\n",
        "\n",
        "        params, img = noisy_circle(200, 50, 2)\n",
        "        img_tensor = img.reshape(200, 200, 1).transpose((2, 0, 1))\n",
        "        tensor = torch.from_numpy(img_tensor)\n",
        "        tensor = tensor.unsqueeze(1).float()\n",
        "        if use_gpu:\n",
        "            tensor = tensor.cuda()\n",
        "        resx = netx(tensor).detach().cpu().numpy()[0]\n",
        "        resy = nety(tensor).detach().cpu().numpy()[0]\n",
        "        resr = netr(tensor).detach().cpu().numpy()[0]\n",
        "        img = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "        rr, cc, val = circle_perimeter_aa(int(resx), int(resy), int(resr))\n",
        "        valid = (\n",
        "            (rr >= 0) &\n",
        "            (rr < img.shape[0]) &\n",
        "            (cc >= 0) &\n",
        "            (cc < img.shape[1])\n",
        "        )\n",
        "\n",
        "        img[rr[valid], cc[valid], 0] = 255\n",
        "        img[rr[valid], cc[valid], 1] = 0\n",
        "        img[rr[valid], cc[valid], 2] = 0\n",
        "\n",
        "        rr, cc, val = circle_perimeter_aa(params[0], params[1], params[2])\n",
        "        valid = (\n",
        "            (rr >= 0) &\n",
        "            (rr < img.shape[0]) &\n",
        "            (cc >= 0) &\n",
        "            (cc < img.shape[1])\n",
        "        )\n",
        "\n",
        "        img[rr[valid], cc[valid], 0] = 0\n",
        "        img[rr[valid], cc[valid], 1] = 255\n",
        "        img[rr[valid], cc[valid], 2] = 0\n",
        "\n",
        "        print(iou((int(resx), int(resy), int(resr)), params))\n",
        "        plt.imshow(img)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def iou_loss(predict, target):\n",
        "    predict = predict.detach().cpu().numpy()\n",
        "    target = target.detach().cpu().numpy()\n",
        "    predict_arr = np.zeros((predict.shape[0], 1, 200, 200), dtype=np.float)\n",
        "    target_arr = np.zeros((predict.shape[0], 1, 200, 200), dtype=np.float)\n",
        "    for i in range(predict.shape[0]):\n",
        "        p = predict[i]\n",
        "        t = target[i]\n",
        "        rr1, cc1 = circle(p[0], p[1], p[2])\n",
        "        rr2, cc2 = circle(t[0], t[1], t[2])\n",
        "        valid1 = (\n",
        "            (rr1 >= 0) &\n",
        "            (rr1 < 200) &\n",
        "            (cc1 >= 0) &\n",
        "            (cc1 < 200)\n",
        "        )\n",
        "        valid2 = (\n",
        "            (rr2 >= 0) &\n",
        "            (rr2 < 200) &\n",
        "            (cc2 >= 0) &\n",
        "            (cc2 < 200)\n",
        "        )\n",
        "        circle1 = np.zeros((200, 200), dtype=np.float)\n",
        "        circle2 = np.zeros((200, 200), dtype=np.float)\n",
        "        circle1[rr1[valid1], cc1[valid1]] = 1\n",
        "        circle2[rr2[valid2], cc2[valid2]] = 1\n",
        "        predict_arr[i,0,:,:] = circle1\n",
        "        target_arr[i,0,:,:] = circle2\n",
        "    predict = torch.tensor(predict_arr, requires_grad=True)\n",
        "    target = torch.tensor(target_arr, requires_grad=True)\n",
        "\n",
        "    intersect = predict * target\n",
        "    intersect = intersect.view(predict.shape[0], 1, -1).sum(2)\n",
        "    union = predict + target - (predict * target)\n",
        "    union = union.view(predict.shape[0], 1, -1).sum(2)\n",
        "\n",
        "    loss = intersect / union\n",
        "\n",
        "    return 1 - loss.mean()\n",
        "\n",
        "\n",
        "def train_model(models, trainloader, testloader, epochs, criterion, optimizer):\n",
        "    mx, my, mr = models[0], models[1], models[2]\n",
        "    ox, oy, Or = optimizer[0], optimizer[1], optimizer[2]\n",
        "    for e in range(epochs):\n",
        "        running_loss = 0\n",
        "        for images, params in tqdm(trainloader):\n",
        "            mx.train()\n",
        "            my.train()\n",
        "            mr.train()\n",
        "            params = torch.stack(params, 1).float()\n",
        "            if use_gpu:\n",
        "                images = images.cuda()\n",
        "                params = params.cuda()\n",
        "\n",
        "            resx = mx(images.unsqueeze(1).float())\n",
        "            resy = my(images.unsqueeze(1).float())\n",
        "            resr = mr(images.unsqueeze(1).float())\n",
        "\n",
        "            \n",
        "            # loss = criterion(torch.stack((resx, resy, resr), dim=1), params) For IOU loss\n",
        "\n",
        "            lossx = criterion(resx[:,0], params[:,0])\n",
        "            lossy = criterion(resy[:,0], params[:,1])\n",
        "            lossr = criterion(resr[:,0], params[:,2])\n",
        "            ox.zero_grad()\n",
        "            oy.zero_grad()\n",
        "            Or.zero_grad()\n",
        "            lossx.backward()\n",
        "            lossy.backward()\n",
        "            lossr.backward()\n",
        "            \n",
        "            # loss.backward()  # For IOU loss\n",
        "            ox.step()\n",
        "            oy.step()\n",
        "            Or.step()\n",
        "            running_loss += lossx.item() + lossy.item() + lossr.item()\n",
        "            gc.collect()\n",
        "        else:\n",
        "            print(f\"Epoch {e+1}\")\n",
        "            print(f\"Training loss: {running_loss / len(trainloader)}\")\n",
        "            eval_model((mx, my, mr), testloader)\n",
        "            # torch.save(mx.state_dict(), f'q2_checkpoints/q2_checkpoints_large2mx_{e+1}.pt')\n",
        "            # torch.save(my.state_dict(), f'q2_checkpoints/q2_checkpoints_large2my_{e+1}.pt')\n",
        "            # torch.save(mr.state_dict(), f'q2_checkpoints/q2_checkpoints_large2mr_{e+1}.pt')\n",
        "\n",
        "\n",
        "def eval_model(models, testloader):\n",
        "    mx, my, mr = models[0], models[1], models[2]\n",
        "    mx.eval()\n",
        "    my.eval()\n",
        "    mr.eval()\n",
        "    metric = 0\n",
        "    for images, params in testloader:\n",
        "        params = torch.stack(params, 1).float()\n",
        "        if use_gpu:\n",
        "            images = images.cuda()\n",
        "\n",
        "        resx = mx(images.unsqueeze(1).float()).detach().cpu().numpy()[0]\n",
        "        resy = my(images.unsqueeze(1).float()).detach().cpu().numpy()[0]\n",
        "        resr = mr(images.unsqueeze(1).float()).detach().cpu().numpy()[0]\n",
        "        res = (resx, resy, resr)\n",
        "        params = params.numpy()[0]\n",
        "        metric += iou(res, params)\n",
        "    print(f\"Average IoU for test set {metric / len(testloader)}\")\n",
        "\n",
        "\n",
        "def train():\n",
        "    trainset = CircleDataset(200000)\n",
        "    trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4)\n",
        "    testset = CircleDataset(1000)\n",
        "    testloader = DataLoader(testset, batch_size=1, shuffle=True)\n",
        "\n",
        "    netx = Net()\n",
        "    nety = Net()\n",
        "    netr = Net()\n",
        "    if use_gpu:\n",
        "        netx = netx.cuda()\n",
        "        nety = nety.cuda()\n",
        "        netr = netr.cuda()\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    # criterion = iou_loss\n",
        "    optimizerx = optim.Adam(netx.parameters(), lr=0.01)\n",
        "    optimizery = optim.Adam(nety.parameters(), lr=0.01)\n",
        "    optimizerr = optim.Adam(netr.parameters(), lr=0.01)\n",
        "    epochs = 20\n",
        "    train_model((netx, nety, netr), trainloader, testloader, epochs, criterion, (optimizerx, optimizery, optimizerr))\n",
        "    eval_model((netx,nety,netr), testloader)\n",
        "\n",
        "\n",
        "def main(do_train):\n",
        "    if do_train:\n",
        "        train()\n",
        "        exit(0)\n",
        "\n",
        "\n",
        "    results = []\n",
        "    for _ in range(1000):\n",
        "        params, img = noisy_circle(200, 50, 2)\n",
        "        detected = find_circle(img)\n",
        "        results.append(iou(params, detected))\n",
        "    results = np.array(results)\n",
        "    print(results.mean())\n",
        "    print((results > 0.7).mean()) \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz09YcfiRJQT",
        "colab_type": "text"
      },
      "source": [
        "## 2.4 Visualization and error analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZXc6zBrRJQT",
        "colab_type": "text"
      },
      "source": [
        "# 3.Hot Dog or Not Hot Dog"
      ]
    }
  ]
}